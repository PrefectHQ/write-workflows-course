<h1>Why Prefect?</h1>

<p>Prefect is a Python-based orchestrator that helps you create resilient
    workflows.</p>

<p>In today&#39;s data-driven world, trust is the bedrock upon which every decision, insight, and product rests.&nbsp;
</p>

<p>Business value is created in a growing long tail of custom, data-intensive workflows that span diverse use cases;
    from personalized customer experiences, to fraud detection, to dynamic pricing.&nbsp;</p>

<p>Data teams face the challenge of navigating risk from more and more potential points
    of failure, while building scalable data practices.</p>

<p>Prefect provides workflow orchestration for the modern data enterprise. With just a
    few lines of code, data teams can confidently automate any data process and gain visibility across their
    technology stack.</p>

<p>When things do go wrong, you can retry failing workflows, get notified, and
    automatically switch to alternative infrastructure.</p>

<h2>Prefect Cloud</h2>

<p>Prefect provides an open source solution for data teams. If you don&#39;t want to
    think about scaling a database, want the user management features enterprises need, and want to go from
    orchestration to global understanding of your technology stack, you want Prefect Cloud.</p>

<p>By automating over 200 million data tasks monthly, Prefect Cloud empowers all types
    of&nbsp;organizations &mdash; from Fortune 50 leaders such as Progressive Insurance to innovative disruptors
    such as Cash App &mdash; to increase engineering productivity, reduce pipeline errors, and cut data workflow
    compute costs.</p>

<p>Instead of a trying to maintain home-grown scripts or duct-taping a legacy orchestrator, you can rely on
    Prefect&#39;s battle-tested open-source core with millions of downloads and over 18,000 GitHub stars.</p>

<h2>Traditional workflow orchestration challenges Prefect solves</h2>

<h3>Not Pythonic</h3>
Learning and writing framework instead of idiomatic Python takes time and mental overhead. For example, writing a DAG in
Airflow requires using operators and avoiding branching logic - at least without contortions. The DAG framework limits
workflow authors because it requires pre-defined DAGs.

<h3>Local development challenges</h3>
Legacy orchestrators such as Airflow, tightly couple workflow logic to the underlying infrastructure. This makes it
difficult to move off your machine to other infrastructure. It also means local testing is difficult.

<h3>Infrastructure costs are unnecessarily high</h3>
Scaling up and down with a legacy orchestrator is difficult. You end up paying for resources that are idle most of the
time.

<h3>Event-driven architecture is not supported</h3>
An organization's data workflows are genally a combination of batch and event-driven processes. Airflow 3 says it
supports event-driven architecture, but in practice it is polling-based.